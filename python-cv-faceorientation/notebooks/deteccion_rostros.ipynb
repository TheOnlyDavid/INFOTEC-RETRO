{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8affa0e0",
   "metadata": {},
   "source": [
    "# Procesamiento y detección de puntos de referencia faciales\n",
    "\n",
    "Este notebook tiene como objetivo procesar una carpeta de imágenes para:\n",
    "\n",
    "1. Detectar puntos clave del rostro (como nariz) usando la API de visión de OpenAI.\n",
    "2. Modificar el prompt para que se identifiquen dichos puntos con coordenadas exactas.\n",
    "3. Bajar la resolución de las imágenes para acelerar el procesamiento y reducir costos.\n",
    "4. Ordenar las imágenes de forma consistente\n",
    "5. Recortar las imágenes centradas en los puntos clave detectados para una mejor visualización o análisis posterior en el pdf auto generado.\n",
    "\n",
    "Cada paso está debidamente documentado con funciones específicas.\n",
    "\n",
    "https://platform.openai.com/docs/guides/images-vision?api-mode=responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503a127",
   "metadata": {},
   "source": [
    "## 0. Configuración inicial\n",
    "Antes de comenzar con el procesamiento de imágenes, es necesario configurar el entorno de trabajo:\n",
    "\n",
    "- Se importan las librerías necesarias, tanto para manejo de archivos, imágenes y conexión con la API de OpenAI.\n",
    "- Se cargan las variables de entorno desde un archivo `.env`, donde debe estar la clave de API (`OPENAI_API_KEY`) y cualquier otro parámetro sensible.\n",
    "- Se inicializa el cliente de OpenAI.\n",
    "- Se definen los directorios de entrada (`SRC_DIR`) y salida (`DST_DIR`) donde se encuentran las imágenes originales y donde se guardarán las imágenes redimensionadas.\n",
    "- Se establece la resolución objetivo (`TARGET_WIDTH`) para estandarizar el tamaño de las imágenes.\n",
    "\n",
    "Este paso garantiza que el flujo posterior (resize, codificación, análisis con la API, etc.) se pueda ejecutar de forma ordenada y reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397bf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Librerías necesarias ---\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import base64\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps, ImageDraw\n",
    "\n",
    "from reportlab.lib.pagesizes import A4, landscape\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.units import cm\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7713abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cargar variables de entorno ---\n",
    "load_dotenv()\n",
    "\n",
    "# --- Inicializar cliente OpenAI ---\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "OPENAI_ASSISTANT_ID = os.getenv(\"OPENAI_ASSISTANT_ID\")  # si lo vas a usar más adelante\n",
    "\n",
    "# --- Directorios de trabajo ---\n",
    "SRC_DIR = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/sineditar\"\n",
    "DST_DIR = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/resized\"\n",
    "os.makedirs(DST_DIR, exist_ok=True)\n",
    "\n",
    "# --- Parámetros de redimensionado ---\n",
    "TARGET_WIDTH = 1350\n",
    "valid_extensions = ('.jpg', '.jpeg')  # extensiones válidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aad1e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(src_path, dst_path, target_width):\n",
    "    \"\"\"\n",
    "    Redimensiona una imagen a un ancho específico manteniendo la proporción.\n",
    "\n",
    "    Args:\n",
    "        src_path (str): Ruta de la imagen original.\n",
    "        dst_path (str): Ruta donde se guardará la imagen redimensionada.\n",
    "        target_width (int): Ancho deseado en píxeles.\n",
    "    \"\"\"\n",
    "    img = Image.open(src_path)\n",
    "    img = ImageOps.exif_transpose(img)  # corrige orientación según EXIF\n",
    "    w_percent = target_width / img.width\n",
    "    target_height = int(img.height * w_percent)\n",
    "    img_resized = img.resize((target_width, target_height), Image.LANCZOS)\n",
    "    img_resized.save(dst_path)\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f243bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Codifica una imagen en base64 para usarla en la API de OpenAI.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Ruta de la imagen.\n",
    "\n",
    "    Returns:\n",
    "        str: Cadena codificada en base64.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ec73b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre las imágenes del directorio y aplicar resize\n",
    "for img_path in glob.glob(os.path.join(SRC_DIR, \"*\")):\n",
    "    if img_path.lower().endswith(valid_extensions):\n",
    "        filename = os.path.basename(img_path)\n",
    "        dst_path = os.path.join(DST_DIR, filename)\n",
    "        resize_image(img_path, dst_path, TARGET_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4b128",
   "metadata": {},
   "source": [
    "## 2. Procesamiento de imágenes con la API de OpenAI\n",
    "\n",
    "En este paso se envían las imágenes redimensionadas a la API de OpenAI para:\n",
    "\n",
    "- Detectar la cantidad de ojos visibles.\n",
    "- Determinar la posición de la cabeza y la expresión facial.\n",
    "- Obtener coordenadas de la punta de la nariz.\n",
    "- Evaluar la calidad de la imagen (calificación entre 0 y 1).\n",
    "\n",
    "Se utiliza un prompt estructurado que pide a la API responder en formato JSON estandarizado.  \n",
    "Todos los resultados se almacenan en una lista y posteriormente en un DataFrame para su análisis o exportación.\n",
    "\n",
    "Este paso es clave para el análisis facial automatizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1d781d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt para clasificación facial y puntos clave\n",
    "prompt = \"\"\"\n",
    "Recibe una imagen de un sujeto y realiza lo siguiente:\n",
    "\n",
    "0. Ojos visibles:\n",
    "   - Analiza cuántos ojos se aprecian:\n",
    "     * Si hay 2 ojos visibles ➔ sigue al paso 1\n",
    "     * Si hay 1 ojo visible ➔ posición = “Perfil izquierda” si mira a la izquierda desde la perspectiva de nosotros o \n",
    "        “Perfil derecha” si mira a la derecha desde la perspectiva de nosotros \n",
    "     * NA (no se puede determinar o no es la foto del rostro de una persona)\n",
    "\n",
    "1. Clasificación facial (solo si hay 2 ojos o no aplicó paso 0):\n",
    "   - Posición de la cabeza (elige UNA):\n",
    "     * Frente (rostro frontal, ambos ojos simétricos y visibles)\n",
    "     * Girado izquierda (ambos ojos visibles, cabeza girada hacia la izquierda, >50% del rostro visible)\n",
    "     * Girado derecha (ambos ojos visibles, cabeza girada hacia la derecha, >50% del rostro visible)\n",
    "     * NA (no se puede determinar o no es la foto del rostro de una persona)\n",
    "\n",
    "   - Expresión facial (elige UNA):\n",
    "     * Sin dentadura (boca cerrada o apenas entreabierta sin dientes visibles)\n",
    "     * Con dentadura (dentadura visible claramente)\n",
    "     * NA (no se puede determinar)\n",
    "\n",
    "2. Detección de puntos clave:\n",
    "   - nariz: coordenada en pixeles [x, y] de la punta de la nariz, o \"NA\" si no es detectable\n",
    "   - calificación: número real entre 0 y 1 que evalúa la calidad de la imagen\n",
    "\n",
    "Formato de salida ÚNICAMENTE un array JSON con un objeto así:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"nombre_archivo\": \"IMG_1234.JPG\",\n",
    "    \"posicion\": \"Perfil izquierda\",\n",
    "    \"expresion\": \"Sin dentadura\",\n",
    "    \"nariz\": [150, 550],\n",
    "    \"calificacion\": 0.85\n",
    "  }\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c85a8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para guardar los resultados\n",
    "results = []\n",
    "\n",
    "# Iterar sobre las imágenes redimensionadas\n",
    "for filename in os.listdir(DST_DIR):\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        image_path = os.path.join(DST_DIR, filename)\n",
    "        image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "        # Construir el input para el modelo\n",
    "        input_data = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"input_text\", \"text\": f\"{prompt}\\nImagen: {filename}\"},\n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": f\"data:image/jpeg;base64,{image_base64}\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Hacer la solicitud a la API\n",
    "        response = client.responses.create(\n",
    "            model=\"o4-mini\",  # o el modelo que estés usando\n",
    "            reasoning={\"effort\": \"high\"},\n",
    "            input=input_data\n",
    "        )\n",
    "\n",
    "        # Extraer la respuesta\n",
    "        if hasattr(response, 'output'):\n",
    "            result = response.output[1].content[0].text  # Ajusta esto si cambia el formato\n",
    "\n",
    "            try:\n",
    "                # Convertir string a objeto Python\n",
    "                data = eval(result) if isinstance(result, str) else result\n",
    "\n",
    "                if isinstance(data, dict):\n",
    "                    results.append(data)\n",
    "                elif isinstance(data, list):\n",
    "                    results.extend(data)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando la respuesta de {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0821b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con resultados\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Guardar en CSV\n",
    "df.to_csv('/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/notebooks/data_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdaeb0a",
   "metadata": {},
   "source": [
    "## 3. Recorte de Imágenes\n",
    "\n",
    "En esta sección se realiza el recorte de las imágenes originales con el objetivo de centrar el rostro del paciente utilizando como referencia la posición de la nariz. El recorte se hace de manera dinámica, adaptado a cada tipo de pose (frontal, perfil, girado, etc.).\n",
    "\n",
    "### Variables utilizadas para el recorte\n",
    "\n",
    "- `left`, `right`: determinan el ancho del recorte a partir del centro de la nariz.\n",
    "- `top`, `bottom`: determinan el alto del recorte hacia arriba y hacia abajo desde la nariz.\n",
    "\n",
    "Estas variables están definidas de forma personalizada por tipo de pose en el diccionario `recortes_por_posicion`.\n",
    "\n",
    "### Relación de aspecto\n",
    "\n",
    "Se busca mantener una relación de aspecto uniforme en las imágenes resultantes, cercana a **3:4 (ancho:alto)**. Para conseguirlo:\n",
    "\n",
    "- Se mantiene constante el alto del recorte (`top + bottom`, aproximadamente 2350 px).\n",
    "- Se ajustan los valores de `left` y `right` para lograr un ancho total de aproximadamente 1760 px.\n",
    "\n",
    "Con esto, se garantiza que las imágenes mantengan una proporción visual coherente y que el rostro del paciente siempre quede bien centrado, sin perder las zonas de interés facial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b901e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuración ---\n",
    "csv_path = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/notebooks/data.csv\"\n",
    "img_folder = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/sineditar\"\n",
    "output_folder = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/fotos_finales\"\n",
    "resized_width_csv = 1350\n",
    "\n",
    "recortes_por_posicion = {\n",
    "    \"Perfil izquierda\":    {\"left\": 400, \"right\": 1360, \"top\": 1400, \"bottom\": 950},\n",
    "    \"Girado izquierda\":    {\"left\": 600, \"right\": 1160, \"top\": 1400, \"bottom\": 950},\n",
    "    \"Frente\":              {\"left\": 880, \"right\": 880,  \"top\": 1400, \"bottom\": 950},\n",
    "    \"Girado derecha\":      {\"left\": 1160, \"right\": 600, \"top\": 1400, \"bottom\": 950},\n",
    "    \"Perfil derecha\":      {\"left\": 1360, \"right\": 400, \"top\": 1400, \"bottom\": 950}\n",
    "}\n",
    "\n",
    "posiciones_deseadas = list(recortes_por_posicion.keys())\n",
    "expresiones_deseadas = [\"Sin dentadura\", \"Con dentadura\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpeta de salida si no existe\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Leer CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# --- Función de recorte dinámico ---\n",
    "def crop_relative_to_nose(img, nose_coord, l, r, t, b):\n",
    "    x, y = nose_coord\n",
    "    left = max(x - l, 0)\n",
    "    upper = max(y - t, 0)\n",
    "    right = min(x + r, img.width)\n",
    "    lower = min(y + b, img.height)\n",
    "    return img.crop((left, upper, right, lower))\n",
    "\n",
    "# --- Procesamiento principal ---\n",
    "for expresion in expresiones_deseadas:\n",
    "    for pos in posiciones_deseadas:\n",
    "        subset = df[(df['expresion'] == expresion) & (df['posicion'] == pos)]\n",
    "        if not subset.empty:\n",
    "            row = subset.iloc[0]\n",
    "            nombre = row['nombre_archivo']\n",
    "            nariz_resized = ast.literal_eval(row['nariz'])\n",
    "            src_path = os.path.join(img_folder, nombre)\n",
    "\n",
    "            if os.path.exists(src_path):\n",
    "                try:\n",
    "                    img = Image.open(src_path)\n",
    "                    img = ImageOps.exif_transpose(img)\n",
    "\n",
    "                    # Escalar coordenadas\n",
    "                    scale_factor = img.width / resized_width_csv\n",
    "                    nariz_original = (\n",
    "                        int(nariz_resized[0] * scale_factor),\n",
    "                        int(nariz_resized[1] * scale_factor)\n",
    "                    )\n",
    "\n",
    "                    # Obtener márgenes personalizados\n",
    "                    recorte = recortes_por_posicion[pos]\n",
    "                    img_cropped = crop_relative_to_nose(\n",
    "                        img,\n",
    "                        nariz_original,\n",
    "                        recorte[\"left\"],\n",
    "                        recorte[\"right\"],\n",
    "                        recorte[\"top\"],\n",
    "                        recorte[\"bottom\"]\n",
    "                    )\n",
    "\n",
    "                    # Guardar\n",
    "                    nombre_base = f\"cropped_{expresion.replace(' ', '_')}_{nombre}\"\n",
    "                    out_path = os.path.join(output_folder, nombre_base)\n",
    "                    img_cropped.save(out_path)\n",
    "                    print(f\"Recortada: {nombre} | {pos} | Expresión: {expresion}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error con {nombre}: {e}\")\n",
    "            else:\n",
    "                print(f\"No encontrada: {nombre}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e76c63",
   "metadata": {},
   "source": [
    "## 4. Generación de PDF ordenado con imágenes\n",
    "\n",
    "En este paso se genera un PDF con las imágenes organizadas de forma visualmente clara para su presentación.\n",
    "\n",
    "### Estructura del PDF:\n",
    "- **Página 1 (vertical)**: Imagen frontal del sujeto con dentadura, centrada y acompañada de datos como nombre, edad y fecha.\n",
    "- **Página 2 (horizontal)**: 2 filas de imágenes:\n",
    "  - Fila superior: imágenes con expresión *sin dentadura* en orden de posición (perfil, girado, frente...).\n",
    "  - Fila inferior: imágenes *con dentadura* en el mismo orden.\n",
    "\n",
    "Este formato ayuda a mostrar la variedad de tomas faciales de manera sistemática.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3f79059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rutas ---\n",
    "csv_path = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/notebooks/data.csv\"\n",
    "img_folder = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/fotos_finales\"\n",
    "output_pdf = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/output_fotos_finales.pdf\"\n",
    "\n",
    "# Leer CSV\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35589fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PÁGINA 1 ===\n",
    "c = canvas.Canvas(output_pdf, pagesize=A4)\n",
    "w, h = A4\n",
    "\n",
    "frontal = df[(df['posicion'] == 'Frente') & (df['expresion'] == 'Con dentadura')].iloc[0]\n",
    "filename = f\"cropped_Con_dentadura_{frontal['nombre_archivo']}\"\n",
    "img_path = os.path.join(img_folder, filename)\n",
    "\n",
    "img = Image.open(img_path)\n",
    "if img.width > img.height:\n",
    "    img = img.rotate(90, expand=True)\n",
    "    img.save(img_path)\n",
    "\n",
    "# Ajustar tamaño manteniendo aspecto\n",
    "img_width = 12 * cm\n",
    "aspect = img.height / img.width\n",
    "img_height = img_width * aspect\n",
    "\n",
    "# Coordenadas centradas\n",
    "x_img = (w - img_width) / 2\n",
    "y_img = h - img_height - 6*cm\n",
    "\n",
    "# Dibujar sombra DETRÁS (como marco expandido)\n",
    "shadow_margin = 0.2 * cm\n",
    "c.saveState()\n",
    "c.setFillColor(Color(0, 0, 0, alpha=0.2))  # sombra negra 20%\n",
    "c.rect(x_img - shadow_margin,\n",
    "       y_img - shadow_margin,\n",
    "       img_width + 2 * shadow_margin,\n",
    "       img_height + 2 * shadow_margin,\n",
    "       fill=1, stroke=0)\n",
    "c.restoreState()\n",
    "\n",
    "# Dibujar imagen encima\n",
    "c.drawImage(img_path, x_img, y_img, width=img_width, height=img_height)\n",
    "\n",
    "# Texto\n",
    "c.setFont(\"Helvetica\", 16)\n",
    "c.setFillColor(black)\n",
    "c.drawCentredString(w / 2, y_img - 1.5*cm, \"SEBASTIAN MORA AGUILERA\")\n",
    "c.setFont(\"Helvetica\", 12)\n",
    "c.drawString(2*cm, y_img - 3*cm, \"EDAD: 10 AÑOS\")\n",
    "c.drawString(8*cm, y_img - 3*cm, \"FECHA DE NACIMIENTO: 08/03/2015\")\n",
    "c.drawString(2*cm, y_img - 3.8*cm, \"FECHA DE TOMA: 17/05/2025\")\n",
    "c.drawString(2*cm, y_img - 4.6*cm, \"DRA. CLAUDIA RIVERO MARIN\")\n",
    "c.showPage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc6ac786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PÁGINA 2 ===\n",
    "c.setPageSize(landscape(A4))\n",
    "w, h = landscape(A4)\n",
    "\n",
    "orden = [\"Perfil izquierda\", \"Girado izquierda\", \"Frente\", \"Girado derecha\", \"Perfil derecha\"]\n",
    "sin_dent = df[df['expresion'] == \"Sin dentadura\"].copy()\n",
    "con_dent = df[df['expresion'] == \"Con dentadura\"].copy()\n",
    "\n",
    "def get_ordered(filtrado, expresion):\n",
    "    resultado = []\n",
    "    for pos in orden:\n",
    "        match = filtrado[filtrado['posicion'] == pos]\n",
    "        if not match.empty:\n",
    "            nombre = match.iloc[0]['nombre_archivo']\n",
    "            archivo = f\"cropped_{expresion.replace(' ', '_')}_{nombre}\"\n",
    "            resultado.append(archivo)\n",
    "    return resultado\n",
    "\n",
    "row1 = get_ordered(sin_dent, \"Sin dentadura\")\n",
    "row2 = get_ordered(con_dent, \"Con dentadura\")\n",
    "\n",
    "# Ajustar tamaño y separación para que entren bien\n",
    "num_imgs = len(orden)\n",
    "margin_horizontal = 1.5 * cm\n",
    "available_width = w - 2 * margin_horizontal\n",
    "max_img_width = 5.5 * cm  # reducir si se salen\n",
    "gap = (available_width - num_imgs * max_img_width) / (num_imgs - 1)\n",
    "\n",
    "x_start = margin_horizontal\n",
    "x_offset = 1 * cm  # Mover todo a la derecha para centrar mejor\n",
    "\n",
    "# Fila 1\n",
    "y1 = h - 4 * cm - max_img_width\n",
    "for i, filename in enumerate(row1):\n",
    "    img_path = os.path.join(img_folder, filename)\n",
    "    if os.path.exists(img_path):\n",
    "        img = Image.open(img_path)\n",
    "        if img.width > img.height:\n",
    "            img = img.rotate(90, expand=True)\n",
    "            img.save(img_path)\n",
    "        \n",
    "        aspect = img.height / img.width\n",
    "        if aspect >= 1:\n",
    "            img_height = max_img_width\n",
    "            img_width = img_height / aspect\n",
    "        else:\n",
    "            img_width = max_img_width\n",
    "            img_height = img_width * aspect\n",
    "        \n",
    "        x = x_start + i * (max_img_width + gap) + x_offset\n",
    "        c.drawImage(img_path, x, y1 + (max_img_width - img_height)/2, width=img_width, height=img_height)\n",
    "\n",
    "# Fila 2\n",
    "y2 = y1 - max_img_width - 1.8 * cm\n",
    "for i, filename in enumerate(row2):\n",
    "    img_path = os.path.join(img_folder, filename)\n",
    "    if os.path.exists(img_path):\n",
    "        img = Image.open(img_path)\n",
    "        if img.width > img.height:\n",
    "            img = img.rotate(90, expand=True)\n",
    "            img.save(img_path)\n",
    "        \n",
    "        aspect = img.height / img.width\n",
    "        if aspect >= 1:\n",
    "            img_height = max_img_width\n",
    "            img_width = img_height / aspect\n",
    "        else:\n",
    "            img_width = max_img_width\n",
    "            img_height = img_width * aspect\n",
    "        \n",
    "        x = x_start + i * (max_img_width + gap) + x_offset\n",
    "        c.drawImage(img_path, x, y2 + (max_img_width - img_height)/2, width=img_width, height=img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "567d7355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF generado con imágenes finales en: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/output_fotos_finales.pdf\n"
     ]
    }
   ],
   "source": [
    "c.save()\n",
    "print(f\"PDF generado con imágenes finales en: {output_pdf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89486b27",
   "metadata": {},
   "source": [
    "## Axuliar - nariz en imágenes\n",
    "\n",
    "Lee el CSV con las coordenadas de nariz, dibuja un círculo rojo en cada imagen donde haya nariz detectada, y guarda una copia marcada en otra carpeta.\n",
    "\n",
    "- Usa `ast.literal_eval` para convertir las coordenadas tipo string a lista.\n",
    "- Dibuja un círculo rojo con `PIL.ImageDraw`.\n",
    "- Guarda las nuevas imágenes con prefijo `marcada_`.\n",
    "\n",
    "Solo marca si hay nariz válida y si la imagen existe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b2288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas\n",
    "csv_path = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/notebooks/data.csv\"\n",
    "img_folder = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/resized\"\n",
    "output_folder = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/resized_marcadas\"\n",
    "\n",
    "# Crear carpeta de salida si no existe\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Leer CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Iterar sobre las imágenes\n",
    "for _, row in df.iterrows():\n",
    "    nombre = row['nombre_archivo']\n",
    "    nariz_raw = row['nariz']\n",
    "    if pd.isna(nariz_raw):\n",
    "        continue  # Saltar si no hay coordenada\n",
    "    \n",
    "    try:\n",
    "        nariz = ast.literal_eval(nariz_raw)\n",
    "        img_path = os.path.join(img_folder, nombre)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Imagen no encontrada: {nombre}\")\n",
    "            continue\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        # Dibuja un círculo rojo de radio 8 px\n",
    "        r = 8\n",
    "        x, y = nariz\n",
    "        draw.ellipse((x - r, y - r, x + r, y + r), fill='red')\n",
    "\n",
    "        # Guardar imagen modificada\n",
    "        out_path = os.path.join(output_folder, f\"marcada_{nombre}\")\n",
    "        img.save(out_path)\n",
    "        print(f\"Nariz marcada en: {nombre}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error con {nombre}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b0324c",
   "metadata": {},
   "source": [
    "## Reflexiones y posibles mejoras\n",
    "\n",
    "Algunas ideas para optimizar y mejorar el flujo de trabajo actual:\n",
    "\n",
    "- **Paralelización de llamadas a la API:**  \n",
    "    Actualmente, las imágenes se procesan de forma secuencial, lo que puede ser muy lento si el número de fotos es grande. Implementar procesamiento en paralelo (por ejemplo, usando `concurrent.futures.ThreadPoolExecutor` o `asyncio` si la librería lo permite) podría reducir significativamente el tiempo total de espera.\n",
    "\n",
    "- **Reducir tokens en las respuestas:**  \n",
    "    El prompt puede modificarse para que la API devuelva códigos cortos en lugar de cadenas largas. Por ejemplo:\n",
    "        - \"Perfil izquierda\" → \"PI\"\n",
    "        - \"Girado izquierda\" → \"GI\"\n",
    "        - \"Frente\" → \"F\"\n",
    "        - \"Girado derecha\" → \"GD\"\n",
    "        - \"Perfil derecha\" → \"PD\"\n",
    "        - \"Sin dentadura\" → \"SD\"\n",
    "        - \"Con dentadura\" → \"CD\"  \n",
    "    Esto reduce el tamaño de la respuesta y, por lo tanto, el costo por token.\n",
    "\n",
    "- **Manejo de valores nulos:**  \n",
    "    En vez de usar \"NA\" para valores no detectados, utilizar `null` (en JSON) o `None` (en Python) facilita el análisis posterior y la integración con pandas.\n",
    "\n",
    "- **Filtrado previo en el prompt:**  \n",
    "    Se puede modificar el prompt para que la API omita imágenes que no sean rostros válidos o que no cumplan ciertos criterios, evitando así respuestas innecesarias y ahorrando tokens.\n",
    "\n",
    "Implementar estas mejoras puede hacer el proceso más eficiente, económico y robusto.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altorendimiento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
