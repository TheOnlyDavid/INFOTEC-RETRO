{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5278457",
   "metadata": {},
   "source": [
    "### Pasos a seguir\n",
    "\n",
    "1. Bajar resolucion de imagenes para reducir costos (Python)\n",
    "2. Orgnizar imagenes (Python)\n",
    "3. Pasar imagenes a asistente para clasificar (OpenAI)\n",
    "    - Pedir también el centro de la cara como un punto dentro de la imagen para obtener el \"centro\" de la imagen para centrar recortar posterior a la detección\n",
    "4. Ordenar imagenes (Python)\n",
    "    - Definir una funcion para centrar el rostro en python (este paso lo dejamos como mejoras a futuro)\n",
    "5. Crear documento (Python)\n",
    "\n",
    "Final --- Juntar todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3564785e",
   "metadata": {},
   "source": [
    "### Precios de imágenes:\n",
    "https://openai.com/api/pricing/\n",
    "\n",
    "Asistentes \n",
    " - https://platform.openai.com/assistants/asst_lFBaNBuv7qFsLzIoeKKh7vpY\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f04d2",
   "metadata": {},
   "source": [
    "Para un asistente de clasificación de imágenes como “Detección de Rostros”, conviene hacerlo lo más determinista posible, así que sí, bajar tanto la temperature como el top_p ayuda a que las respuestas sean consistentes y sin variaciones innecesarias.\n",
    "\n",
    "temperature: ponla en un valor muy bajo, por ejemplo 0 o 0.1. Así el modelo elegirá siempre la opción más probable.\n",
    "\n",
    "top_p: también puedes reducirla a alrededor de 0.8 o incluso 0.5 si quieres acotar aún más las posibles salidas. Si la dejas en 1.0, funcionará bien, pero con valores menores restringes el rango de tokens considerados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda361b1",
   "metadata": {},
   "source": [
    "# Escalar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d288622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardada: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_7530aaa3838b3135fb60e1df0ceb8fee.JPG\n",
      "Guardada: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_3ad2f98e1075b76bfa9e69963f957385.JPG\n",
      "Guardada: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_2ee77858f2bb3f0f2effa4717ba33863.JPG\n",
      "Guardada: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_5a9e480a8788dd5a5dae2025e25e475d.JPG\n",
      "Guardada: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_e5c8253b917c53ff27a9ea8625d6a845.JPG\n",
      "Guardada: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_5d7e0fe35521b61f82c2164788e822f1.JPG\n",
      "Guardada: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_d84e8e89a12027cf764183a6fce45f75.JPG\n",
      "Guardada: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_00b880189f5efe4752ea19c4ac1feaa3.JPG\n",
      "Guardada: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_9c264c48f5112691fcdfecc0efa39ccd.JPG\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import glob\n",
    "\n",
    "SRC_DIR = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente\"\n",
    "DST_DIR = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized\"\n",
    "os.makedirs(DST_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_WIDTH = 800\n",
    "\n",
    "def resize_image(src_path, dst_path, target_width):\n",
    "    img = Image.open(src_path)\n",
    "    # Corrige la orientación según EXIF\n",
    "    img = ImageOps.exif_transpose(img)\n",
    "    # Calcula la nueva altura manteniendo proporción\n",
    "    w_percent = (target_width / img.width)\n",
    "    target_height = int(img.height * w_percent)\n",
    "    # Redimensiona\n",
    "    img_resized = img.resize((target_width, target_height), Image.LANCZOS)\n",
    "    # Guarda (por defecto mantiene formato JPEG, PNG, etc.)\n",
    "    img_resized.save(dst_path)\n",
    "    img.close()\n",
    "\n",
    "for img_path in glob.glob(os.path.join(SRC_DIR, \"*.*\")):\n",
    "    filename = os.path.basename(img_path)\n",
    "    dst_path = os.path.join(DST_DIR, filename)\n",
    "    resize_image(img_path, dst_path, TARGET_WIDTH)\n",
    "    print(f\"Guardada: {dst_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02733a77",
   "metadata": {},
   "source": [
    "# API ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8c6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Inicializa el cliente\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "OPENAI_ASSISTANT_ID = os.getenv(\"OPENAI_ASSISTANT_ID\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab8504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Recibe un lote de imágenes del mismo sujeto y realiza dos tareas por imagen:\n",
    "\n",
    "1 - Clasificación facial:\n",
    "Posición de la cabeza: Elige una sola opción entre las siguientes:\n",
    "- Perfil completo a la izquierda\n",
    "- Perfil completo a la derecha\n",
    "- Ligeramente girado a la izquierda\n",
    "- Ligeramente girado a la derecha\n",
    "- Frente\n",
    "\n",
    "Expresión facial: Elige una sola opción entre las siguientes:\n",
    "- Sin mostrar dentadura (serio o neutro)\n",
    "- Mostrando dentadura (sonrisa abierta)\n",
    "\n",
    "2 - Detección de puntos clave:\n",
    "Identifica las coordenadas (x, y) en píxeles de al menos los siguientes puntos anatómicos visibles:\n",
    "- Punta de la nariz\n",
    "- Centro de la boca (entre los labios)\n",
    "- Centro de la frente (aproximadamente entre las cejas)\n",
    "\n",
    "Manejo de imágenes borrosas o ambiguas:\n",
    "Si la imagen está demasiado borrosa o la cabeza está en una posición ambigua, escribe \"indefinida\" tanto en posición como en expresión.\n",
    "También indica \"puntos no detectados\" si no puedes identificar de forma confiable las coordenadas.\n",
    "\n",
    "Formato de salida:\n",
    "\n",
    "Por cada imagen válida, genera una línea con el siguiente formato:\n",
    "nombre_del_archivo: posición – <posición>, expresión – <expresión>, nariz – (x, y), boca – (x, y), frente – (x, y)\n",
    "\n",
    "Además, necesito un total de 10 imágenes: una por cada combinación de posición de cabeza y expresión facial (5 posiciones × 2 expresiones).\n",
    "Solo selecciona las 10 mejores imágenes que representen claramente cada categoría.\n",
    "Si hay imágenes duplicadas, borrosas o de menor calidad comparadas con otras, indícalo explícitamente y menciona que serán descartadas o ignoradas por esas razones.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4e64e2",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e1ee02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_assistant(thread):\n",
    "    # Retrieve the Assistant\n",
    "    assistant = client.beta.assistants.retrieve(OPENAI_ASSISTANT_ID)\n",
    "\n",
    "    # Run the assistant\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        # instructions=f\"You are having a conversation with {name}\",\n",
    "    )\n",
    "\n",
    "    # Wait for completion\n",
    "    # https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps#:~:text=under%20failed_at.-,Polling%20for%20updates,-In%20order%20to\n",
    "    while run.status != \"completed\":\n",
    "        # Be nice to the API\n",
    "        time.sleep(0.5)\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    # Retrieve the Messages\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    new_message = messages.data[0].content[0].text.value\n",
    "    return new_message\n",
    "\n",
    "def generate_response(message_body):\n",
    "    # Check if there is already a thread_id for the wa_id\n",
    "    thread_id = None\n",
    "\n",
    "    # If a thread doesn't exist, create one and store it\n",
    "    if thread_id is None:\n",
    "        thread = client.beta.threads.create()\n",
    "        thread_id = thread.id\n",
    "\n",
    "    # Otherwise, retrieve the existing thread\n",
    "    else:\n",
    "        thread = client.beta.threads.retrieve(thread_id)\n",
    "\n",
    "    # Add message to thread\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=message_body,\n",
    "    )\n",
    "\n",
    "    # Run the assistant and get the new message\n",
    "    new_message = run_assistant(thread)\n",
    "\n",
    "    return new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9850fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_body = \"Hola, ¿me escuchas?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "571cca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_response(message_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb3147d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola! Sí, te escucho. ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8109627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "img_path = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_00b880189f5efe4752ea19c4ac1feaa3.JPG\"\n",
    "with open(img_path, \"rb\") as image_file:\n",
    "    b64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# prompt = \"What is in this image?\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"data:image/png;base64,{b64_image}\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81c04276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagen1.jpg: posición – ligeramente girado a la derecha, expresión – mostrando dentadura\n"
     ]
    }
   ],
   "source": [
    "print(response.output[1].content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f41956d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "img_path = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_3ad2f98e1075b76bfa9e69963f957385.JPG\"\n",
    "with open(img_path, \"rb\") as image_file:\n",
    "    b64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# prompt = \"What is in this image?\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"data:image/png;base64,{b64_image}\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61899f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagen1.jpg: posición – perfil completo a la derecha, expresión – sin mostrar dentadura\n"
     ]
    }
   ],
   "source": [
    "print(response.output[1].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ea2f55",
   "metadata": {},
   "source": [
    "# Tests 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f03ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "img_path = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_00b880189f5efe4752ea19c4ac1feaa3.JPG\"\n",
    "with open(img_path, \"rb\") as image_file:\n",
    "    b64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# prompt = \"What is in this image?\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"data:image/png;base64,{b64_image}\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb13abd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_68277d4292e88191b91cbbe5f324c1450b572fd42b0a69ca', created_at=1747418434.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='o4-mini-2025-04-16', object='response', output=[ResponseReasoningItem(id='rs_68277d43645081918adfabbfa58beafb0b572fd42b0a69ca', summary=[], type='reasoning', encrypted_content=None, status=None), ResponseOutputMessage(id='msg_68277d4b7b6881918778e2b53922ace40b572fd42b0a69ca', content=[ResponseOutputText(annotations=[], text='imagen1.jpg: posición – ligeramente girado a la derecha, expresión – mostrando dentadura', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=1760, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=472, output_tokens_details=OutputTokensDetails(reasoning_tokens=448), total_tokens=2232), user=None, store=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd706309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Rutas de las imágenes\n",
    "img_path_1 = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_00b880189f5efe4752ea19c4ac1feaa3.JPG\"\n",
    "img_path_2 = \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_2ee77858f2bb3f0f2effa4717ba33863.JPG\"\n",
    "\n",
    "# Codificación en base64\n",
    "b64_image_1 = encode_image_to_base64(img_path_1)\n",
    "b64_image_2 = encode_image_to_base64(img_path_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c619cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# prompt = \"What is in this image?\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"data:image/png;base64,{b64_image_1}\"},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"data:image/png;base64,{b64_image_2}\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f831c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foto1.jpg: posición – ligeramente girado a la derecha, expresión – mostrando dentadura  \n",
      "foto2.jpg: posición – ligeramente girado a la izquierda, expresión – mostrando dentadura\n"
     ]
    }
   ],
   "source": [
    "print(response.output[1].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf459039",
   "metadata": {},
   "source": [
    "# Ordenar en doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a027234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF generado en: /Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/notebooks/comparacion_jose_landscape.pdf\n"
     ]
    }
   ],
   "source": [
    "from reportlab.lib.pagesizes import A4, landscape\n",
    "from reportlab.pdfgen import canvas\n",
    "import os\n",
    "\n",
    "def images_to_pdf(img_paths, output_path):\n",
    "    # Página en horizontal (A4 landscape)\n",
    "    width, height = landscape(A4)\n",
    "    c = canvas.Canvas(output_path, pagesize=(width, height))\n",
    "\n",
    "    # Márgenes y espacio\n",
    "    margin = 40\n",
    "    usable_width = width / 2 - 2 * margin   # ancho de cada columna\n",
    "    usable_height = (height - 3 * margin) / 2  # alto de cada fila (2 filas)\n",
    "\n",
    "    # Coordenadas para la columna izquierda\n",
    "    x = margin\n",
    "    y_top = height - margin - usable_height\n",
    "    y_bottom = margin\n",
    "\n",
    "    # Para cada imagen, calculamos escala manteniendo ratio\n",
    "    def draw_image(path, x, y):\n",
    "        img_width, img_height = c.drawImage(path, x, y, width=0, height=0, preserveAspectRatio=True, mask='auto')\n",
    "        # Si la imagen excede el espacio asignado, la escalamos\n",
    "        scale = min(usable_width / img_width, usable_height / img_height, 1)\n",
    "        iw, ih = img_width * scale, img_height * scale\n",
    "        c.drawImage(path, x, y + (usable_height - ih), width=iw, height=ih, preserveAspectRatio=True, mask='auto')\n",
    "\n",
    "    # Dibuja la primera imagen arriba\n",
    "    draw_image(img_paths[0], x, y_top)\n",
    "\n",
    "    # Dibuja la segunda imagen abajo\n",
    "    draw_image(img_paths[1], x, y_bottom)\n",
    "\n",
    "    c.showPage()\n",
    "    c.save()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    imgs = [\n",
    "        \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_00b880189f5efe4752ea19c4ac1feaa3.JPG\",\n",
    "        \"/Users/aaron/Documentos/INFOTEC RETRO/python-cv-faceorientation/img/jose/frente_resized/JOSE_MARIO_MORENO_ZAVALA_2ee77858f2bb3f0f2effa4717ba33863.JPG\",\n",
    "    ]\n",
    "    out_pdf = \"comparacion_jose_landscape.pdf\"\n",
    "    images_to_pdf(imgs, out_pdf)\n",
    "    print(f\"PDF generado en: {os.path.abspath(out_pdf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea4a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa91e5ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4664050",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altorendimiento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
